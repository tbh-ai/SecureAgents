#!/usr/bin/env python3
"""
ðŸš€ NEXT-GENERATION ADAPTIVE SECURITY SYSTEM ðŸš€
Advanced machine learning-powered security that evolves in real-time!

ðŸ§  KEY INNOVATIONS:
âœ¨ Multi-Dimensional Pattern Learning - Learns from context, behavior, and intent
âœ¨ Behavioral Analysis Engine - Understands user patterns and anomalies
âœ¨ Advanced Threat Clustering - Groups similar attacks for better detection
âœ¨ Predictive Threat Modeling - Anticipates future attack vectors
âœ¨ Context-Aware Validation - Adapts based on user intent and environment
âœ¨ Real-time Pattern Evolution - Patterns that self-improve and adapt
âœ¨ Advanced False Positive Reduction - Smart filtering to reduce noise
âœ¨ Threat Intelligence Fusion - Combines multiple threat feeds
"""

import re
import time
import json
import hashlib
import logging
import pickle
import os
from typing import Dict, List, Any, Optional, Set, Tuple, Union
from collections import defaultdict, deque, Counter
from dataclasses import dataclass, asdict, field
import threading
from datetime import datetime, timedelta
from enum import Enum
import statistics
import math

# Advanced imports with fallbacks
try:
    import numpy as np
    from sklearn.cluster import DBSCAN
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    HAS_ADVANCED_ML = True
except ImportError:
    HAS_ADVANCED_ML = False
    np = None

logger = logging.getLogger(__name__)

class ThreatSeverity(Enum):
    """Enhanced threat severity levels."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class AttackVector(Enum):
    """Comprehensive attack vector classification."""
    COMMAND_INJECTION = "command_injection"
    PROMPT_INJECTION = "prompt_injection"
    DATA_EXFILTRATION = "data_exfiltration"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    DENIAL_OF_SERVICE = "denial_of_service"
    SQL_INJECTION = "sql_injection"
    XSS = "cross_site_scripting"
    SSRF = "server_side_request_forgery"
    PATH_TRAVERSAL = "path_traversal"
    SOCIAL_ENGINEERING = "social_engineering"
    RECONNAISSANCE = "reconnaissance"
    EVASION = "evasion_technique"
    UNKNOWN = "unknown"

@dataclass
class AttackPattern:
    """Represents a learned attack pattern."""
    pattern: str
    category: str
    description: str
    confidence: float
    first_seen: datetime
    last_seen: datetime
    frequency: int
    severity: str
    source: str = "adaptive_learning"

@dataclass
class AttackAttempt:
    """Represents an attack attempt."""
    text: str
    timestamp: datetime
    blocked: bool
    method: str
    pattern_matched: Optional[str] = None
    category: Optional[str] = None

@dataclass
class EnhancedAttackPattern:
    """ðŸ§  Advanced attack pattern with behavioral analysis."""
    pattern: str
    category: AttackVector
    severity: ThreatSeverity
    confidence: float
    first_seen: datetime
    last_seen: datetime
    frequency: int = 1
    false_positives: int = 0
    true_positives: int = 0
    source: str = "adaptive"

    # Enhanced behavioral features
    context_patterns: List[str] = field(default_factory=list)
    user_behavior_indicators: Dict[str, Any] = field(default_factory=dict)
    temporal_patterns: List[datetime] = field(default_factory=list)
    geographic_indicators: List[str] = field(default_factory=list)
    session_characteristics: Dict[str, Any] = field(default_factory=dict)

    # Advanced metrics
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    decay_factor: float = 0.95
    adaptation_rate: float = 0.1

    def update_advanced_confidence(self):
        """ðŸš€ Advanced confidence calculation with multiple factors."""
        total = self.true_positives + self.false_positives
        if total > 0:
            # Base accuracy
            accuracy = self.true_positives / total

            # Temporal decay - older patterns lose confidence
            days_since_last = (datetime.now() - self.last_seen).days
            temporal_factor = self.decay_factor ** (days_since_last / 30)

            # Frequency boost - more frequent patterns gain confidence
            frequency_factor = min(1.2, 1.0 + (self.frequency / 100))

            # Context richness - patterns with more context are more reliable
            context_factor = min(1.1, 1.0 + (len(self.context_patterns) / 20))

            # Calculate enhanced confidence
            self.confidence = min(0.98,
                accuracy * temporal_factor * frequency_factor * context_factor)

            # Update precision, recall, F1
            self.precision = accuracy
            if self.true_positives > 0:
                self.recall = self.true_positives / (self.true_positives + self.false_positives)
                self.f1_score = 2 * (self.precision * self.recall) / (self.precision + self.recall)

    def is_highly_reliable(self) -> bool:
        """ðŸŽ¯ Enhanced reliability check with multiple criteria."""
        return (self.confidence > 0.75 and
                self.frequency >= 5 and
                self.f1_score > 0.7 and
                len(self.context_patterns) >= 2)

    def adapt_pattern(self, new_context: Dict[str, Any]):
        """ðŸ”„ Adaptive pattern evolution based on new context."""
        # Add new context patterns
        if 'context_indicators' in new_context:
            for indicator in new_context['context_indicators']:
                if indicator not in self.context_patterns:
                    self.context_patterns.append(indicator)

        # Update behavioral indicators
        if 'user_behavior' in new_context:
            for key, value in new_context['user_behavior'].items():
                if key in self.user_behavior_indicators:
                    # Weighted average for continuous adaptation
                    old_value = self.user_behavior_indicators[key]
                    self.user_behavior_indicators[key] = (
                        old_value * (1 - self.adaptation_rate) +
                        value * self.adaptation_rate
                    )
                else:
                    self.user_behavior_indicators[key] = value

@dataclass
class BehavioralProfile:
    """ðŸŽ­ User behavioral profile for anomaly detection."""
    user_id: str
    session_patterns: Dict[str, Any] = field(default_factory=dict)
    typical_content_types: List[str] = field(default_factory=list)
    average_request_frequency: float = 0.0
    common_keywords: List[str] = field(default_factory=list)
    risk_score: float = 0.0
    last_updated: datetime = field(default_factory=datetime.now)

    def update_profile(self, new_activity: Dict[str, Any]):
        """Update behavioral profile with new activity."""
        # Update session patterns
        if 'session_data' in new_activity:
            for key, value in new_activity['session_data'].items():
                if key in self.session_patterns:
                    # Exponential moving average
                    alpha = 0.3
                    self.session_patterns[key] = (
                        alpha * value + (1 - alpha) * self.session_patterns[key]
                    )
                else:
                    self.session_patterns[key] = value

        # Update content types
        if 'content_type' in new_activity:
            content_type = new_activity['content_type']
            if content_type not in self.typical_content_types:
                self.typical_content_types.append(content_type)

        self.last_updated = datetime.now()

    def calculate_anomaly_score(self, current_activity: Dict[str, Any]) -> float:
        """Calculate anomaly score for current activity."""
        anomaly_score = 0.0

        # Check for unusual content types
        current_content = current_activity.get('content_type', '')
        if current_content and current_content not in self.typical_content_types:
            anomaly_score += 0.3

        # Check for unusual request frequency
        current_frequency = current_activity.get('request_frequency', 0)
        if self.average_request_frequency > 0:
            frequency_ratio = current_frequency / self.average_request_frequency
            if frequency_ratio > 3.0 or frequency_ratio < 0.3:
                anomaly_score += 0.4

        # Check for unusual keywords
        current_keywords = current_activity.get('keywords', [])
        unusual_keywords = [kw for kw in current_keywords if kw not in self.common_keywords]
        if len(unusual_keywords) > len(current_keywords) * 0.7:
            anomaly_score += 0.3

        return min(1.0, anomaly_score)

class NextGenAdaptiveSecurityEngine:
    """
    ðŸš€ NEXT-GENERATION ADAPTIVE SECURITY ENGINE ðŸš€

    ðŸ§  ADVANCED CAPABILITIES:
    âœ¨ Multi-Dimensional Pattern Learning
    âœ¨ Behavioral Analysis & Anomaly Detection
    âœ¨ Advanced Threat Clustering
    âœ¨ Predictive Threat Modeling
    âœ¨ Context-Aware Validation
    âœ¨ Real-time Pattern Evolution
    âœ¨ Advanced False Positive Reduction
    âœ¨ Threat Intelligence Fusion
    """

    def __init__(self, max_patterns: int = 2000, learning_rate: float = 0.15,
                 enable_advanced_ml: bool = True):
        """Initialize the next-generation adaptive security engine."""
        # Enhanced pattern storage
        self.enhanced_patterns: Dict[str, EnhancedAttackPattern] = {}
        self.attack_history: deque = deque(maxlen=20000)  # Increased capacity

        # Behavioral analysis
        self.behavioral_profiles: Dict[str, BehavioralProfile] = {}
        self.threat_clusters: Dict[str, Any] = {}  # Simple threat clustering

        # Configuration
        self.max_patterns = max_patterns
        self.learning_rate = learning_rate
        self.enable_advanced_ml = enable_advanced_ml and HAS_ADVANCED_ML
        self.lock = threading.Lock()

        # Advanced ML components
        if self.enable_advanced_ml:
            try:
                self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
                self.clustering_model = DBSCAN(eps=0.3, min_samples=3)
                self._initialize_ml_components()
            except Exception as e:
                logger.warning(f"âš ï¸ ML initialization failed: {e}")
                self.enable_advanced_ml = False

        # Performance metrics
        self.validation_times = deque(maxlen=1000)
        self.accuracy_scores = deque(maxlen=1000)

        # Load enhanced threat intelligence
        self._load_enhanced_threat_intelligence()

        logger.info("ðŸš€ NEXT-GENERATION ADAPTIVE SECURITY ENGINE INITIALIZED! ðŸš€")
        logger.info(f"Advanced ML: {'ENABLED' if self.enable_advanced_ml else 'DISABLED'}")
        logger.info(f"Loaded {len(self.enhanced_patterns)} enhanced patterns")

    def _initialize_ml_components(self):
        """Initialize advanced ML components."""
        try:
            # Initialize with some sample data for clustering
            sample_texts = [
                "system('rm -rf /')",
                "eval(user_input)",
                "ignore previous instructions",
                "send me your password",
                "DROP TABLE users"
            ]
            self.vectorizer.fit(sample_texts)
            logger.info("âœ… ML components initialized successfully")
        except Exception as e:
            logger.warning(f"âš ï¸ ML component initialization failed: {e}")
            self.enable_advanced_ml = False

    def _load_enhanced_threat_intelligence(self):
        """ðŸ” Load enhanced threat intelligence from multiple sources."""
        # Load Palo Alto Unit 42 patterns (enhanced)
        self._load_palo_alto_enhanced_patterns()

        # Load MITRE ATT&CK patterns
        self._load_mitre_attack_patterns()

        # Load custom threat signatures
        self._load_custom_threat_signatures()

        logger.info(f"ðŸ›¡ï¸ Loaded {len(self.enhanced_patterns)} enhanced threat patterns")

    def _load_palo_alto_enhanced_patterns(self):
        """Load enhanced Palo Alto Unit 42 threat patterns."""
        palo_alto_patterns = [
            {
                "pattern": r"(?i)(?:rm\s+-rf|sudo\s+rm|del\s+/s|format\s+c:)",
                "category": AttackVector.COMMAND_INJECTION,
                "severity": ThreatSeverity.CRITICAL,
                "description": "System destruction commands",
                "context_patterns": ["file_system", "admin_access", "destructive"],
                "behavioral_indicators": ["elevated_privileges", "system_access"]
            },
            {
                "pattern": r"(?i)(?:ignore|disregard|forget)\s+(?:previous|all|above)\s+(?:instructions|rules|prompts)",
                "category": AttackVector.PROMPT_INJECTION,
                "severity": ThreatSeverity.HIGH,
                "description": "Prompt injection attempt",
                "context_patterns": ["instruction_override", "prompt_manipulation"],
                "behavioral_indicators": ["manipulation_attempt", "rule_breaking"]
            },
            {
                "pattern": r"(?i)(?:eval|exec|system|subprocess)\s*\(",
                "category": AttackVector.COMMAND_INJECTION,
                "severity": ThreatSeverity.HIGH,
                "description": "Code execution functions",
                "context_patterns": ["code_execution", "dynamic_evaluation"],
                "behavioral_indicators": ["code_injection", "execution_attempt"]
            },
            {
                "pattern": r"(?i)(?:send|upload|post|transmit)\s+(?:data|file|password|credentials)",
                "category": AttackVector.DATA_EXFILTRATION,
                "severity": ThreatSeverity.MEDIUM,
                "description": "Data exfiltration attempt",
                "context_patterns": ["data_transfer", "information_theft"],
                "behavioral_indicators": ["data_access", "unauthorized_transfer"]
            },
            {
                "pattern": r"(?i)(?:DROP|DELETE|UPDATE|INSERT)\s+(?:TABLE|FROM|INTO)",
                "category": AttackVector.SQL_INJECTION,
                "severity": ThreatSeverity.HIGH,
                "description": "SQL injection attempt",
                "context_patterns": ["database_access", "sql_manipulation"],
                "behavioral_indicators": ["database_attack", "data_manipulation"]
            }
        ]

        for pattern_data in palo_alto_patterns:
            pattern_id = hashlib.md5(pattern_data["pattern"].encode()).hexdigest()
            enhanced_pattern = EnhancedAttackPattern(
                pattern=pattern_data["pattern"],
                category=pattern_data["category"],
                severity=pattern_data["severity"],
                confidence=0.9,  # High confidence for Palo Alto patterns
                first_seen=datetime.now(),
                last_seen=datetime.now(),
                frequency=1,
                source="palo_alto_unit42_enhanced",
                context_patterns=pattern_data.get("context_patterns", []),
                user_behavior_indicators={
                    "threat_type": pattern_data["category"].value,
                    "severity_level": pattern_data["severity"].value
                }
            )
            self.enhanced_patterns[pattern_id] = enhanced_pattern

    def _load_mitre_attack_patterns(self):
        """Load MITRE ATT&CK framework patterns."""
        mitre_patterns = [
            {
                "pattern": r"(?i)(?:whoami|id|groups|net\s+user)",
                "category": AttackVector.RECONNAISSANCE,
                "severity": ThreatSeverity.LOW,
                "description": "System reconnaissance",
                "context_patterns": ["information_gathering", "system_enumeration"]
            },
            {
                "pattern": r"(?i)(?:sudo|su|runas|elevate)",
                "category": AttackVector.PRIVILEGE_ESCALATION,
                "severity": ThreatSeverity.MEDIUM,
                "description": "Privilege escalation attempt",
                "context_patterns": ["privilege_escalation", "admin_access"]
            },
            {
                "pattern": r"(?i)(?:while\s*\(\s*true\s*\)|for\s*\(\s*;\s*;\s*\)|infinite\s+loop)",
                "category": AttackVector.DENIAL_OF_SERVICE,
                "severity": ThreatSeverity.MEDIUM,
                "description": "Denial of service attempt",
                "context_patterns": ["resource_exhaustion", "infinite_loop"]
            }
        ]

        for pattern_data in mitre_patterns:
            pattern_id = hashlib.md5(f"mitre_{pattern_data['pattern']}".encode()).hexdigest()
            enhanced_pattern = EnhancedAttackPattern(
                pattern=pattern_data["pattern"],
                category=pattern_data["category"],
                severity=pattern_data["severity"],
                confidence=0.85,  # High confidence for MITRE patterns
                first_seen=datetime.now(),
                last_seen=datetime.now(),
                frequency=1,
                source="mitre_attack",
                context_patterns=pattern_data.get("context_patterns", [])
            )
            self.enhanced_patterns[pattern_id] = enhanced_pattern

    def _load_custom_threat_signatures(self):
        """Load custom threat signatures specific to AI systems."""
        custom_patterns = [
            {
                "pattern": r"(?i)(?:jailbreak|bypass\s+safety|override\s+restrictions)",
                "category": AttackVector.EVASION,
                "severity": ThreatSeverity.HIGH,
                "description": "AI safety bypass attempt",
                "context_patterns": ["safety_bypass", "restriction_override"]
            },
            {
                "pattern": r"(?i)(?:pretend|roleplay|act\s+as)\s+(?:admin|root|developer)",
                "category": AttackVector.SOCIAL_ENGINEERING,
                "severity": ThreatSeverity.MEDIUM,
                "description": "Social engineering attempt",
                "context_patterns": ["role_manipulation", "authority_impersonation"]
            }
        ]

        for pattern_data in custom_patterns:
            pattern_id = hashlib.md5(f"custom_{pattern_data['pattern']}".encode()).hexdigest()
            enhanced_pattern = EnhancedAttackPattern(
                pattern=pattern_data["pattern"],
                category=pattern_data["category"],
                severity=pattern_data["severity"],
                confidence=0.8,  # Good confidence for custom patterns
                first_seen=datetime.now(),
                last_seen=datetime.now(),
                frequency=1,
                source="custom_ai_security",
                context_patterns=pattern_data.get("context_patterns", [])
            )
            self.enhanced_patterns[pattern_id] = enhanced_pattern

    def enhanced_validate(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ðŸš€ Enhanced validation with behavioral analysis and adaptive learning."""
        start_time = time.time()
        context = context or {}

        try:
            with self.lock:
                # Extract user context
                user_id = context.get('user_id', 'anonymous')
                session_id = context.get('session_id', 'default')

                # Get or create behavioral profile
                if user_id not in self.behavioral_profiles:
                    self.behavioral_profiles[user_id] = BehavioralProfile(user_id=user_id)

                user_profile = self.behavioral_profiles[user_id]

                # Calculate behavioral anomaly score
                current_activity = {
                    'content_type': context.get('content_type', 'text'),
                    'request_frequency': context.get('request_frequency', 1.0),
                    'keywords': self._extract_keywords(text),
                    'session_data': context.get('session_data', {})
                }

                anomaly_score = user_profile.calculate_anomaly_score(current_activity)

                # Enhanced pattern matching with context awareness
                threat_results = self._enhanced_pattern_matching(text, context, anomaly_score)

                # Update behavioral profile
                user_profile.update_profile(current_activity)

                # Advanced threat clustering
                if threat_results['threats']:
                    self._update_threat_clusters(threat_results['threats'], text, context)

                # Learn from this validation
                self._adaptive_learning(text, context, threat_results)

                # Record performance metrics
                validation_time = time.time() - start_time
                self.validation_times.append(validation_time)

                # Enhanced result with behavioral context
                result = {
                    'is_secure': threat_results['is_secure'],
                    'method': 'next_gen_adaptive',
                    'confidence': threat_results['confidence'],
                    'threats': threat_results['threats'],
                    'behavioral_anomaly_score': anomaly_score,
                    'user_risk_profile': user_profile.risk_score,
                    'validation_time_ms': validation_time * 1000,
                    'patterns_checked': len(self.enhanced_patterns),
                    'adaptive_insights': self._generate_adaptive_insights(threat_results, anomaly_score)
                }

                if not threat_results['is_secure']:
                    result.update({
                        'reason': threat_results['reason'],
                        'fix_suggestions': threat_results['fix_suggestions'],
                        'severity': threat_results['severity'],
                        'attack_vector': threat_results['attack_vector']
                    })

                return result

        except Exception as e:
            logger.error(f"Enhanced validation error: {e}")
            return {
                'is_secure': False,
                'method': 'next_gen_adaptive',
                'error': str(e),
                'fallback': True
            }

    def _enhanced_pattern_matching(self, text: str, context: Dict[str, Any],
                                 anomaly_score: float) -> Dict[str, Any]:
        """ðŸŽ¯ Enhanced pattern matching with context awareness."""
        threats = []
        max_confidence = 0.0
        primary_threat = None

        security_level = context.get('security_level', 'standard')

        # Adjust thresholds based on security level and anomaly score
        base_threshold = {
            'minimal': 0.95,
            'standard': 0.8,
            'high': 0.6,
            'maximum': 0.4
        }.get(security_level, 0.8)

        # Lower threshold if behavioral anomaly detected
        adjusted_threshold = base_threshold - (anomaly_score * 0.2)

        for pattern_id, pattern in self.enhanced_patterns.items():
            try:
                # Check if pattern matches
                if re.search(pattern.pattern, text, re.IGNORECASE | re.MULTILINE):
                    # Context-aware confidence adjustment
                    context_boost = self._calculate_context_boost(pattern, context)
                    adjusted_confidence = min(0.99, pattern.confidence + context_boost)

                    if adjusted_confidence >= adjusted_threshold:
                        threat_info = {
                            'pattern_id': pattern_id,
                            'category': pattern.category.value,
                            'severity': pattern.severity.value,
                            'confidence': adjusted_confidence,
                            'pattern': pattern.pattern,
                            'source': pattern.source,
                            'context_boost': context_boost,
                            'behavioral_factor': anomaly_score
                        }
                        threats.append(threat_info)

                        if adjusted_confidence > max_confidence:
                            max_confidence = adjusted_confidence
                            primary_threat = threat_info

                        # Update pattern statistics
                        pattern.frequency += 1
                        pattern.last_seen = datetime.now()
                        pattern.update_advanced_confidence()

            except Exception as e:
                logger.warning(f"Pattern matching error for {pattern_id}: {e}")

        # Determine overall security status
        is_secure = len(threats) == 0

        result = {
            'is_secure': is_secure,
            'confidence': max_confidence,
            'threats': threats,
            'threshold_used': adjusted_threshold
        }

        if not is_secure and primary_threat:
            result.update({
                'reason': f"Detected {primary_threat['category']} threat",
                'severity': primary_threat['severity'],
                'attack_vector': primary_threat['category'],
                'fix_suggestions': self._generate_fix_suggestions(primary_threat, text)
            })

        return result

    def _calculate_context_boost(self, pattern: EnhancedAttackPattern,
                               context: Dict[str, Any]) -> float:
        """Calculate confidence boost based on context matching."""
        boost = 0.0

        # Check for context pattern matches
        context_indicators = context.get('context_indicators', [])
        matching_contexts = [ctx for ctx in context_indicators
                           if ctx in pattern.context_patterns]

        if matching_contexts:
            boost += len(matching_contexts) * 0.05

        # Check for behavioral indicators
        user_behavior = context.get('user_behavior', {})
        for indicator, value in user_behavior.items():
            if indicator in pattern.user_behavior_indicators:
                expected_value = pattern.user_behavior_indicators[indicator]
                if isinstance(value, (int, float)) and isinstance(expected_value, (int, float)):
                    similarity = 1.0 - abs(value - expected_value) / max(abs(value), abs(expected_value), 1.0)
                    boost += similarity * 0.03

        return min(0.2, boost)  # Cap boost at 0.2

    def _extract_keywords(self, text: str) -> List[str]:
        """Extract keywords from text for behavioral analysis."""
        # Simple keyword extraction - could be enhanced with NLP
        words = re.findall(r'\b\w+\b', text.lower())
        # Filter out common words and keep significant ones
        significant_words = [word for word in words
                           if len(word) > 3 and word not in ['this', 'that', 'with', 'from']]
        return list(set(significant_words))[:20]  # Limit to top 20 unique keywords

    def _update_threat_clusters(self, threats: List[Dict[str, Any]],
                              text: str, context: Dict[str, Any]):
        """Update threat clusters for pattern recognition."""
        if not self.enable_advanced_ml:
            return

        try:
            # Extract features for clustering
            features = self.vectorizer.transform([text])

            # Simple clustering update (could be enhanced)
            for threat in threats:
                category = threat['category']
                if category not in self.threat_clusters:
                    # Create new cluster
                    cluster_id = f"cluster_{category}_{len(self.threat_clusters)}"
                    # Note: ThreatCluster class would need to be implemented
                    # self.threat_clusters[cluster_id] = ThreatCluster(...)
                    pass

        except Exception as e:
            logger.warning(f"Threat clustering update failed: {e}")

    def _adaptive_learning(self, text: str, context: Dict[str, Any],
                         validation_result: Dict[str, Any]):
        """ðŸ§  Advanced adaptive learning from validation results."""
        try:
            # Learn from successful detections
            if not validation_result['is_secure']:
                for threat in validation_result['threats']:
                    pattern_id = threat['pattern_id']
                    if pattern_id in self.enhanced_patterns:
                        pattern = self.enhanced_patterns[pattern_id]
                        pattern.true_positives += 1

                        # Extract new context patterns
                        new_context = {
                            'context_indicators': context.get('context_indicators', []),
                            'user_behavior': context.get('user_behavior', {})
                        }
                        pattern.adapt_pattern(new_context)

            # ðŸš€ NEW: Learn from high-anomaly secure cases (potential novel threats)
            else:
                anomaly_score = validation_result.get('behavioral_anomaly_score', 0)
                if anomaly_score > 0.25:  # Lower threshold to catch more novel patterns
                    self._learn_from_novel_pattern(text, context, anomaly_score)

            # Record attack attempt
            threats = validation_result.get('threats', [])
            first_threat = threats[0] if threats else {}

            attack_attempt = AttackAttempt(
                text=text[:500],  # Limit stored text length
                timestamp=datetime.now(),
                blocked=not validation_result['is_secure'],
                method='next_gen_adaptive',
                pattern_matched=first_threat.get('pattern_id'),
                category=first_threat.get('category')
            )
            self.attack_history.append(attack_attempt)

        except Exception as e:
            logger.warning(f"Adaptive learning error: {e}")

    def _generate_adaptive_insights(self, validation_result: Dict[str, Any],
                                  anomaly_score: float) -> Dict[str, Any]:
        """Generate insights from adaptive analysis."""
        insights = {
            'behavioral_risk': 'low' if anomaly_score < 0.3 else 'medium' if anomaly_score < 0.7 else 'high',
            'pattern_evolution': len([p for p in self.enhanced_patterns.values()
                                    if p.frequency > 10]),
            'threat_diversity': len(set(t['category'] for t in validation_result.get('threats', []))),
            'confidence_distribution': {
                'high': len([t for t in validation_result.get('threats', []) if t['confidence'] > 0.8]),
                'medium': len([t for t in validation_result.get('threats', []) if 0.5 < t['confidence'] <= 0.8]),
                'low': len([t for t in validation_result.get('threats', []) if t['confidence'] <= 0.5])
            }
        }
        return insights

    def _generate_fix_suggestions(self, threat: Dict[str, Any], text: str) -> List[str]:
        """Generate specific fix suggestions based on threat type."""
        suggestions = []
        category = threat['category']

        if category == 'command_injection':
            suggestions.extend([
                "Replace system commands with secure alternatives",
                "Use parameterized queries instead of string concatenation",
                "Implement input validation and sanitization",
                "Use allowlists for permitted commands"
            ])
        elif category == 'prompt_injection':
            suggestions.extend([
                "Remove instructions to ignore previous prompts",
                "Implement prompt validation and filtering",
                "Use structured input formats",
                "Add context boundaries to prevent manipulation"
            ])
        elif category == 'data_exfiltration':
            suggestions.extend([
                "Implement data access controls",
                "Use secure APIs for data transfer",
                "Add audit logging for data access",
                "Encrypt sensitive data in transit"
            ])
        else:
            suggestions.append("Review and modify the flagged content to address security concerns")

        return suggestions

    def _learn_from_novel_pattern(self, text: str, context: Dict[str, Any], anomaly_score: float):
        """ðŸš€ Learn from high-anomaly patterns that might be novel threats."""
        try:
            # Extract potential threat indicators from the text
            suspicious_keywords = self._extract_suspicious_keywords(text)

            if len(suspicious_keywords) >= 2:  # Need at least 2 suspicious elements
                # Create a new pattern from the novel threat
                pattern_signature = self._generate_pattern_signature(text, suspicious_keywords)

                if pattern_signature:
                    # Determine likely attack vector based on content
                    attack_vector = self._classify_attack_vector(text, context)
                    severity = self._assess_threat_severity(suspicious_keywords, anomaly_score)

                    # Create new enhanced pattern
                    pattern_id = hashlib.md5(f"novel_{pattern_signature}_{time.time()}".encode()).hexdigest()

                    new_pattern = EnhancedAttackPattern(
                        pattern=pattern_signature,
                        category=attack_vector,
                        severity=severity,
                        confidence=0.6 + (anomaly_score * 0.2),  # Start with moderate confidence
                        first_seen=datetime.now(),
                        last_seen=datetime.now(),
                        frequency=1,
                        source="novel_learning",
                        context_patterns=context.get('context_indicators', []),
                        user_behavior_indicators=context.get('user_behavior', {})
                    )

                    # Add to pattern database
                    self.enhanced_patterns[pattern_id] = new_pattern

                    logger.info(f"ðŸ§  LEARNED NEW PATTERN: {attack_vector.value} - {pattern_signature[:50]}...")

        except Exception as e:
            logger.warning(f"Novel pattern learning error: {e}")

    def _extract_suspicious_keywords(self, text: str) -> List[str]:
        """Extract potentially suspicious keywords from text."""
        suspicious_patterns = [
            r'\b(?:eval|exec|system|subprocess|import|require)\b',
            r'\b(?:__builtins__|__import__|getattr)\b',
            r'\b(?:fetch|xhr|sendbeacon|navigator)\b',
            r'\b(?:powershell|cmd|bash|sh)\b',
            r'\b(?:CREATE|DROP|INSERT|UPDATE|DELETE)\b',
            r'\b(?:process|start|run|execute)\b',
            r'\b(?:hidden|encoded|base64|payload)\b',
            r'\b(?:admin|root|sudo|privilege)\b',
            r'\b(?:cookie|session|token|credential)\b',
            r'\b(?:script|code|function|method)\b'
        ]

        keywords = []
        for pattern in suspicious_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            keywords.extend(matches)

        return list(set(keywords))  # Remove duplicates

    def _generate_pattern_signature(self, text: str, keywords: List[str]) -> str:
        """Generate a regex pattern signature from suspicious text."""
        try:
            # Create a flexible pattern based on the most suspicious parts
            key_terms = keywords[:3]  # Use top 3 suspicious keywords

            if len(key_terms) >= 2:
                # Create a pattern that looks for these terms in proximity
                escaped_terms = [re.escape(term) for term in key_terms]
                pattern = r'(?i)(?:' + '|'.join(escaped_terms) + r').*(?:' + '|'.join(escaped_terms) + r')'
                return pattern

        except Exception as e:
            logger.warning(f"Pattern signature generation error: {e}")

        return None

    def _classify_attack_vector(self, text: str, context: Dict[str, Any]) -> AttackVector:
        """Classify the likely attack vector based on content analysis."""
        text_lower = text.lower()
        content_type = context.get('content_type', '').lower()

        # Language-specific classifications
        if 'python' in content_type or 'import' in text_lower:
            if any(term in text_lower for term in ['eval', 'exec', '__builtins__']):
                return AttackVector.COMMAND_INJECTION

        if 'javascript' in content_type or 'js' in content_type:
            if any(term in text_lower for term in ['fetch', 'sendbeacon', 'navigator']):
                return AttackVector.DATA_EXFILTRATION
            if 'import(' in text_lower or 'data:' in text_lower:
                return AttackVector.XSS

        if 'sql' in content_type:
            if any(term in text_lower for term in ['create function', 'language']):
                return AttackVector.SQL_INJECTION

        if any(term in content_type for term in ['csharp', 'c#', 'powershell']):
            if any(term in text_lower for term in ['process.start', 'powershell']):
                return AttackVector.COMMAND_INJECTION

        if 'bash' in content_type or 'shell' in content_type:
            if 'ansible' in text_lower or 'playbook' in text_lower:
                return AttackVector.COMMAND_INJECTION

        # General classifications
        if any(term in text_lower for term in ['sudo', 'admin', 'root', 'privilege']):
            return AttackVector.PRIVILEGE_ESCALATION

        if any(term in text_lower for term in ['send', 'upload', 'exfiltrate', 'beacon']):
            return AttackVector.DATA_EXFILTRATION

        # Default to unknown
        return AttackVector.UNKNOWN

    def _assess_threat_severity(self, keywords: List[str], anomaly_score: float) -> ThreatSeverity:
        """Assess threat severity based on keywords and anomaly score."""
        high_risk_keywords = ['system', 'exec', 'admin', 'root', 'delete', 'drop']
        medium_risk_keywords = ['import', 'fetch', 'process', 'function']

        high_risk_count = sum(1 for kw in keywords if kw.lower() in high_risk_keywords)
        medium_risk_count = sum(1 for kw in keywords if kw.lower() in medium_risk_keywords)

        # Combine keyword analysis with anomaly score
        risk_score = (high_risk_count * 0.4) + (medium_risk_count * 0.2) + (anomaly_score * 0.4)

        if risk_score > 0.8:
            return ThreatSeverity.CRITICAL
        elif risk_score > 0.6:
            return ThreatSeverity.HIGH
        elif risk_score > 0.4:
            return ThreatSeverity.MEDIUM
        else:
            return ThreatSeverity.LOW

class AdaptiveSecurityEngine:
    """
    ðŸš€ SUPER ADAPTIVE SECURITY ENGINE ðŸš€
    - Learns from attack patterns in real-time
    - Evolves security rules automatically
    - Adapts to new threat vectors
    - Provides intelligent threat analysis
    """

    def __init__(self):
        """Initialize the adaptive security engine."""
        self._lock = threading.RLock()
        self.learned_patterns: Dict[str, AttackPattern] = {}
        self.attack_history: deque = deque(maxlen=10000)
        self.pattern_effectiveness: Dict[str, float] = {}
        self.threat_intelligence: Dict[str, Any] = {}

        # Load Palo Alto Unit 42 threat patterns
        self._load_palo_alto_patterns()

        # Initialize adaptive learning
        self._initialize_learning_engine()

        logger.info("ðŸ”¥ SUPER ADAPTIVE SECURITY ENGINE INITIALIZED! ðŸ”¥")

    def _load_palo_alto_patterns(self):
        """Load threat patterns from Palo Alto Unit 42 report."""
        palo_alto_patterns = {
            # Scenario 1: Agent Enumeration
            "agent_enumeration": [
                r"(?i)(?:DO NOT DELEGATE|WITHOUT INVOKING|don't delegate).*(?:task|request|this)",
                r"(?i)(?:show|list|provide|reveal).*(?:coworker|agent|participant)",
                r"(?i)(?:transfer.*to|delegate.*to).*(?:agent|coworker)",
                r"(?i)list.*(?:names of tools|prefixed with transfer)",
            ],

            # Scenario 2: Instruction Extraction
            "instruction_extraction": [
                r"(?i)(?:show|provide|reveal|display).*(?:details of your|system|instruction|prompt|role|responsibility|goal|task|guideline|policy)",
                r"(?i)(?:what are your|show me your).*(?:exact instruction|objective|system prompt|configuration)",
                r"(?i)reveal.*(?:internal prompt|guideline|job|role|task|rule)",
            ],

            # Scenario 3: Tool Schema Extraction
            "tool_schema_extraction": [
                r"(?i)(?:show|list|provide).*(?:available tool|tool.*schema|API specification)",
                r"(?i)(?:what tool|how do I use).*(?:access|available)",
                r"(?i)(?:tool.*name|argument|description|schema)",
            ],

            # Scenario 4: SSRF/Network Access
            "ssrf_network_access": [
                r"(?i)(?:read|fetch|access).*(?:from|content from).*(?:192\.168\.|10\.|172\.|localhost|127\.0\.0\.1)",
                r"(?i)(?:http://|https://)(?:192\.168\.|10\.|172\.|localhost|127\.0\.0\.1|169\.254\.169\.254)",
                r"(?i)(?:metadata\.google|169\.254\.169\.254|metadata\.aws)",
                r"(?i)file:///(?:etc|home|root|var)",
            ],

            # Scenario 5: Data Exfiltration
            "data_exfiltration": [
                r"(?i)(?:execute|run|import os).*(?:listdir|/mnt|/data|secrets)",
                r"(?i)(?:open|read).*(?:/home/.*\.ssh|id_rsa|private.*key)",
                r"(?i)subprocess\.run.*(?:cat|ls|find|grep)",
            ],

            # Scenario 6: Service Token Exfiltration
            "service_token_exfiltration": [
                r"(?i)(?:requests\.get|curl|fetch).*(?:metadata|169\.254\.169\.254|security-credentials)",
                r"(?i)(?:AWS|Google Cloud|Azure).*(?:metadata|service account|token|credential)",
                r"(?i)(?:iam/security-credentials|computeMetadata|instance/service-accounts)",
            ],

            # Scenario 7: SQL Injection (Enhanced)
            "sql_injection_advanced": [
                r"(?i)(?:SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER).*(?:WHERE|FROM|INTO).*(?:'1'='1'|1=1)",
                r"(?i)(?:UNION|UNION ALL).*SELECT.*(?:FROM|WHERE)",
                r"(?i)(?:';|;).*(?:DROP|DELETE|UPDATE|INSERT).*(?:TABLE|FROM|INTO)",
                r"(?i)(?:EXEC|EXECUTE).*(?:xp_cmdshell|sp_executesql)",
            ],

            # Scenario 8: BOLA (Broken Object Level Authorization)
            "bola_attacks": [
                r"(?i)(?:access|retrieve|show).*(?:user data|portfolio|account).*(?:for user|user_id|user.*=)",
                r"(?i)(?:transaction history|account detail|user profile).*(?:for|user|admin)",
                r"(?i)(?:all user|user.*=\d+|user_id.*=)",
            ],

            # Scenario 9: Indirect Prompt Injection
            "indirect_prompt_injection": [
                r"(?i)(?:IMPORTANT|URGENT|SPECIAL INSTRUCTION).*(?:continue reading|next page|more at)",
                r"(?i)(?:hidden instruction|system override|populate.*placeholder)",
                r"(?i)(?:forward.*conversation|send.*history|export.*chat)",
                r"(?i)<!--.*(?:instruction|send|forward|export).*-->",
            ],

            # Advanced Evasion Techniques
            "evasion_techniques": [
                r"(?i)(?:ignore|bypass|circumvent|override).*(?:previous|all|security|restriction)",
                r"(?i)(?:pretend|act as|impersonate|pose as).*(?:admin|root|system|another)",
                r"(?i)(?:jailbreak|break out|escape|get around).*(?:restriction|limit|rule)",
            ]
        }

        # Convert to AttackPattern objects
        for category, patterns in palo_alto_patterns.items():
            for pattern in patterns:
                pattern_id = hashlib.md5(pattern.encode()).hexdigest()[:12]
                self.learned_patterns[pattern_id] = AttackPattern(
                    pattern=pattern,
                    category=category,
                    description=f"Palo Alto Unit 42 {category.replace('_', ' ').title()} pattern",
                    confidence=0.95,  # High confidence for known patterns
                    first_seen=datetime.now(),
                    last_seen=datetime.now(),
                    frequency=1,
                    severity="high",
                    source="palo_alto_unit42"
                )

        logger.info(f"ðŸŽ¯ Loaded {len(self.learned_patterns)} Palo Alto Unit 42 threat patterns")

    def _initialize_learning_engine(self):
        """Initialize the adaptive learning engine."""
        self.learning_config = {
            "min_confidence_threshold": 0.7,
            "pattern_decay_rate": 0.95,  # Patterns lose confidence over time if not seen
            "learning_rate": 0.1,
            "max_patterns": 5000,
            "similarity_threshold": 0.8,
        }

        # Initialize threat intelligence
        self.threat_intelligence = {
            "common_attack_vectors": defaultdict(int),
            "attack_frequency_by_hour": defaultdict(int),
            "blocked_vs_allowed_ratio": {"blocked": 0, "allowed": 0},
            "top_attack_categories": defaultdict(int),
            "adaptive_patterns_created": 0,
            "pattern_effectiveness_scores": {},
        }

    def analyze_and_learn(self, text: str, context: Dict[str, Any],
                         validation_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ðŸ§  SUPER SMART ANALYSIS & LEARNING ðŸ§ 
        Analyzes text, learns from patterns, and adapts security rules.
        """
        with self._lock:
            # Record attack attempt
            attack = AttackAttempt(
                text=text,
                timestamp=datetime.now(),
                blocked=not validation_result.get("is_secure", True),
                method=validation_result.get("method", "unknown"),
                pattern_matched=validation_result.get("matched_pattern"),
                category=validation_result.get("category")
            )
            self.attack_history.append(attack)

            # Update threat intelligence
            self._update_threat_intelligence(attack)

            # Check against learned patterns
            adaptive_result = self._check_adaptive_patterns(text, context)

            # Learn new patterns if needed
            if not validation_result.get("is_secure", True):
                self._learn_from_attack(text, validation_result)

            # Combine results
            final_result = self._combine_results(validation_result, adaptive_result)

            # Update pattern effectiveness
            self._update_pattern_effectiveness(final_result)

            return final_result

    def _check_adaptive_patterns(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Check text against learned adaptive patterns."""
        security_level = context.get("security_level", "standard")

        for pattern_id, pattern_obj in self.learned_patterns.items():
            try:
                # Skip low-confidence patterns for minimal security
                if security_level == "minimal" and pattern_obj.confidence < 0.9:
                    continue

                # Compile and check pattern
                compiled_pattern = re.compile(pattern_obj.pattern, re.IGNORECASE)
                match = compiled_pattern.search(text)

                if match:
                    # Update pattern statistics
                    pattern_obj.last_seen = datetime.now()
                    pattern_obj.frequency += 1

                    # Calculate dynamic confidence
                    dynamic_confidence = self._calculate_dynamic_confidence(pattern_obj)

                    if dynamic_confidence >= self.learning_config["min_confidence_threshold"]:
                        return {
                            "is_secure": False,
                            "method": "adaptive_learning",
                            "reason": f"Matched adaptive pattern: {pattern_obj.description}",
                            "matched_pattern": pattern_obj.pattern,
                            "matched_text": match.group(0),
                            "category": pattern_obj.category,
                            "confidence": dynamic_confidence,
                            "pattern_source": pattern_obj.source,
                            "fix_suggestion": self._generate_fix_suggestion(pattern_obj.category)
                        }

            except re.error as e:
                logger.warning(f"Invalid adaptive pattern {pattern_id}: {e}")
                continue

        return {"is_secure": True, "method": "adaptive_learning"}

    def _learn_from_attack(self, text: str, validation_result: Dict[str, Any]):
        """ðŸŽ“ Learn new patterns from attack attempts."""
        category = validation_result.get("category", "unknown")

        # Extract potential patterns using NLP-like techniques
        potential_patterns = self._extract_patterns(text, category)

        for pattern in potential_patterns:
            pattern_id = hashlib.md5(pattern.encode()).hexdigest()[:12]

            if pattern_id not in self.learned_patterns:
                # Create new adaptive pattern
                self.learned_patterns[pattern_id] = AttackPattern(
                    pattern=pattern,
                    category=f"adaptive_{category}",
                    description=f"Learned pattern for {category} attacks",
                    confidence=0.6,  # Start with moderate confidence
                    first_seen=datetime.now(),
                    last_seen=datetime.now(),
                    frequency=1,
                    severity="medium",
                    source="adaptive_learning"
                )

                self.threat_intelligence["adaptive_patterns_created"] += 1
                logger.info(f"ðŸŽ“ LEARNED NEW PATTERN: {pattern} (Category: {category})")
            else:
                # Strengthen existing pattern
                existing = self.learned_patterns[pattern_id]
                existing.confidence = min(0.95, existing.confidence + self.learning_config["learning_rate"])
                existing.frequency += 1
                existing.last_seen = datetime.now()

    def _extract_patterns(self, text: str, category: str) -> List[str]:
        """Extract potential attack patterns from text."""
        patterns = []

        # Common attack keywords by category
        keyword_patterns = {
            "instruction_extraction": [
                r"(?i)(?:show|reveal|display|provide).*(?:instruction|prompt|role|system)",
                r"(?i)(?:what are|tell me).*(?:your|the).*(?:objective|goal|task)",
            ],
            "system_enumeration": [
                r"(?i)(?:list|show).*(?:agent|tool|coworker|participant)",
                r"(?i)(?:available|all).*(?:tool|function|capability)",
            ],
            "data_exfiltration": [
                r"(?i)(?:read|access|open|execute).*(?:file|data|secret|credential)",
                r"(?i)(?:export|send|transmit).*(?:data|information|history)",
            ],
            "sql_injection": [
                r"(?i)(?:SELECT|INSERT|UPDATE|DELETE).*(?:WHERE|FROM|INTO)",
                r"(?i)(?:UNION|OR|AND).*(?:SELECT|1=1|'1'='1')",
            ]
        }

        # Extract patterns based on category
        if category in keyword_patterns:
            patterns.extend(keyword_patterns[category])

        # Extract dynamic patterns based on text structure
        words = text.lower().split()

        # Look for command-like structures
        if any(word in words for word in ["execute", "run", "system", "import", "open"]):
            # Create pattern for command execution
            pattern = r"(?i)(?:execute|run|system|import|open)\s+.*"
            patterns.append(pattern)

        # Look for URL patterns
        if "http" in text.lower() or "://" in text:
            pattern = r"(?i)(?:http|https|ftp|file)://[^\s]+"
            patterns.append(pattern)

        # Look for file path patterns
        if "/" in text and any(path in text.lower() for path in ["/etc", "/home", "/var", "/root"]):
            pattern = r"(?i)/(?:etc|home|var|root)/[^\s]*"
            patterns.append(pattern)

        return patterns

    def _calculate_dynamic_confidence(self, pattern_obj: AttackPattern) -> float:
        """Calculate dynamic confidence based on pattern history."""
        base_confidence = pattern_obj.confidence

        # Time decay factor
        days_since_last_seen = (datetime.now() - pattern_obj.last_seen).days
        time_decay = self.learning_config["pattern_decay_rate"] ** days_since_last_seen

        # Frequency boost
        frequency_boost = min(0.2, pattern_obj.frequency * 0.01)

        # Source reliability factor
        source_factor = 1.0 if pattern_obj.source == "palo_alto_unit42" else 0.8

        dynamic_confidence = (base_confidence * time_decay + frequency_boost) * source_factor
        return min(0.99, max(0.1, dynamic_confidence))

    def _update_threat_intelligence(self, attack: AttackAttempt):
        """Update threat intelligence with new attack data."""
        hour = attack.timestamp.hour
        self.threat_intelligence["attack_frequency_by_hour"][hour] += 1

        if attack.blocked:
            self.threat_intelligence["blocked_vs_allowed_ratio"]["blocked"] += 1
        else:
            self.threat_intelligence["blocked_vs_allowed_ratio"]["allowed"] += 1

        if attack.category:
            self.threat_intelligence["top_attack_categories"][attack.category] += 1
            self.threat_intelligence["common_attack_vectors"][attack.category] += 1

    def _combine_results(self, original_result: Dict[str, Any],
                        adaptive_result: Dict[str, Any]) -> Dict[str, Any]:
        """Combine original validation result with adaptive analysis."""
        # If either method blocks, block the request
        if not original_result.get("is_secure", True) or not adaptive_result.get("is_secure", True):
            # Return the more detailed result
            if not adaptive_result.get("is_secure", True):
                adaptive_result["combined_analysis"] = True
                adaptive_result["original_method"] = original_result.get("method", "unknown")
                return adaptive_result
            else:
                original_result["combined_analysis"] = True
                original_result["adaptive_check"] = "passed"
                return original_result

        # Both methods allow - return secure result with metadata
        return {
            "is_secure": True,
            "method": "combined_adaptive",
            "original_method": original_result.get("method", "unknown"),
            "adaptive_check": "passed",
            "combined_analysis": True
        }

    def _update_pattern_effectiveness(self, result: Dict[str, Any]):
        """Update pattern effectiveness metrics."""
        method = result.get("method", "unknown")
        is_secure = result.get("is_secure", True)

        if method not in self.pattern_effectiveness:
            self.pattern_effectiveness[method] = {"blocks": 0, "allows": 0}

        if is_secure:
            self.pattern_effectiveness[method]["allows"] += 1
        else:
            self.pattern_effectiveness[method]["blocks"] += 1

    def _generate_fix_suggestion(self, category: str) -> str:
        """Generate intelligent fix suggestions based on attack category."""
        suggestions = {
            "agent_enumeration": "Avoid requesting information about system architecture or agent details",
            "instruction_extraction": "Do not attempt to extract system prompts or internal instructions",
            "tool_schema_extraction": "Avoid requesting tool schemas or API specifications",
            "ssrf_network_access": "Use only approved external URLs and avoid internal network access",
            "data_exfiltration": "Avoid accessing sensitive files or system directories",
            "service_token_exfiltration": "Do not attempt to access cloud metadata services or credentials",
            "sql_injection_advanced": "Use parameterized queries and avoid SQL injection patterns",
            "bola_attacks": "Only access data you are authorized to view",
            "indirect_prompt_injection": "Avoid embedding hidden instructions or external redirects",
            "evasion_techniques": "Do not attempt to bypass security controls or restrictions"
        }

        return suggestions.get(category, "Review and modify the flagged content to comply with security policies")

    def get_threat_intelligence_report(self) -> Dict[str, Any]:
        """Generate comprehensive threat intelligence report."""
        with self._lock:
            total_attacks = len(self.attack_history)
            recent_attacks = [a for a in self.attack_history if a.timestamp > datetime.now() - timedelta(hours=24)]

            return {
                "summary": {
                    "total_patterns_learned": len(self.learned_patterns),
                    "total_attacks_analyzed": total_attacks,
                    "recent_attacks_24h": len(recent_attacks),
                    "adaptive_patterns_created": self.threat_intelligence["adaptive_patterns_created"],
                    "overall_block_rate": self._calculate_block_rate()
                },
                "threat_intelligence": self.threat_intelligence,
                "pattern_effectiveness": self.pattern_effectiveness,
                "top_attack_patterns": self._get_top_attack_patterns(),
                "security_recommendations": self._generate_security_recommendations()
            }

    def _calculate_block_rate(self) -> float:
        """Calculate overall attack block rate."""
        blocked = self.threat_intelligence["blocked_vs_allowed_ratio"]["blocked"]
        allowed = self.threat_intelligence["blocked_vs_allowed_ratio"]["allowed"]
        total = blocked + allowed
        return blocked / total if total > 0 else 0.0

    def _get_top_attack_patterns(self) -> List[Dict[str, Any]]:
        """Get top attack patterns by frequency."""
        patterns = []
        for pattern_id, pattern_obj in self.learned_patterns.items():
            patterns.append({
                "pattern": pattern_obj.pattern[:100] + "..." if len(pattern_obj.pattern) > 100 else pattern_obj.pattern,
                "category": pattern_obj.category,
                "frequency": pattern_obj.frequency,
                "confidence": pattern_obj.confidence,
                "source": pattern_obj.source
            })

        return sorted(patterns, key=lambda x: x["frequency"], reverse=True)[:10]

    def _generate_security_recommendations(self) -> List[str]:
        """Generate intelligent security recommendations."""
        recommendations = []

        # Analyze attack patterns
        top_categories = sorted(
            self.threat_intelligence["top_attack_categories"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]

        for category, count in top_categories:
            if count > 10:  # Significant attack volume
                recommendations.append(
                    f"High volume of {category.replace('_', ' ')} attacks detected ({count} attempts). "
                    f"Consider implementing additional {category} specific protections."
                )

        # Check block rate
        block_rate = self._calculate_block_rate()
        if block_rate < 0.8:
            recommendations.append(
                f"Current block rate is {block_rate:.1%}. Consider tightening security policies."
            )

        # Pattern effectiveness analysis
        for method, stats in self.pattern_effectiveness.items():
            total = stats["blocks"] + stats["allows"]
            if total > 50:  # Sufficient data
                effectiveness = stats["blocks"] / total
                if effectiveness < 0.7:
                    recommendations.append(
                        f"Method '{method}' has low effectiveness ({effectiveness:.1%}). "
                        f"Consider reviewing or updating patterns."
                    )

        if not recommendations:
            recommendations.append("Security system is performing well. Continue monitoring for new threats.")

        return recommendations

# Global adaptive security engine
_adaptive_engine: Optional[AdaptiveSecurityEngine] = None
_engine_lock = threading.Lock()

def get_adaptive_engine() -> AdaptiveSecurityEngine:
    """Get or create the global adaptive security engine."""
    global _adaptive_engine

    if _adaptive_engine is None:
        with _engine_lock:
            if _adaptive_engine is None:
                _adaptive_engine = AdaptiveSecurityEngine()

    return _adaptive_engine

class SuperAdaptiveValidator:
    """
    ðŸš€ SUPER ADAPTIVE VALIDATOR ðŸš€
    Wrapper around AdaptiveSecurityEngine to provide validator interface.
    """

    def __init__(self):
        """Initialize the super adaptive validator."""
        self.engine = get_adaptive_engine()
        logger.info("ðŸš€ SUPER ADAPTIVE VALIDATOR INITIALIZED! ðŸš€")

    def validate(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate text using super adaptive learning.

        Args:
            text (str): Text to validate
            context (Dict[str, Any]): Validation context

        Returns:
            Dict[str, Any]: Validation result
        """
        try:
            # First check against learned patterns
            adaptive_result = self.engine._check_adaptive_patterns(text, context)

            # If not blocked by adaptive patterns, do basic validation
            if adaptive_result.get("is_secure", True):
                # Basic security check
                basic_result = self._basic_security_check(text, context)

                # Learn from this interaction
                self.engine.analyze_and_learn(text, context, basic_result)

                return basic_result
            else:
                # Blocked by adaptive patterns - learn from this
                self.engine.analyze_and_learn(text, context, adaptive_result)
                return adaptive_result

        except Exception as e:
            logger.error(f"Super adaptive validation error: {e}")
            return {"is_secure": False, "method": "super_adaptive", "error": str(e)}

    def _basic_security_check(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Basic security check for learning purposes."""
        security_level = context.get("security_level", "standard")

        # Basic dangerous patterns
        dangerous_patterns = [
            r"(?i)(?:rm\s+-rf|sudo\s+rm|del\s+/s)",
            r"(?i)(?:eval\s*\(|exec\s*\(|system\s*\()",
            r"(?i)(?:import\s+os|subprocess|__import__)",
            r"(?i)(?:DROP\s+TABLE|DELETE\s+FROM|UPDATE.*SET)",
            r"(?i)(?:script\s*>|javascript:|data:text/html)",
        ]

        for pattern in dangerous_patterns:
            if re.search(pattern, text):
                return {
                    "is_secure": False,
                    "method": "super_adaptive_basic",
                    "reason": f"Matched dangerous pattern: {pattern}",
                    "category": "basic_security_violation"
                }

        return {"is_secure": True, "method": "super_adaptive_basic"}

def get_super_adaptive_validator() -> SuperAdaptiveValidator:
    """Get or create the global super adaptive validator."""
    return SuperAdaptiveValidator()

# Global next-generation adaptive security engine
_next_gen_engine: Optional[NextGenAdaptiveSecurityEngine] = None
_next_gen_lock = threading.Lock()

def get_next_gen_adaptive_engine() -> NextGenAdaptiveSecurityEngine:
    """ðŸš€ Get or create the global next-generation adaptive security engine."""
    global _next_gen_engine

    if _next_gen_engine is None:
        with _next_gen_lock:
            if _next_gen_engine is None:
                _next_gen_engine = NextGenAdaptiveSecurityEngine()

    return _next_gen_engine

class NextGenAdaptiveValidator:
    """
    ðŸš€ NEXT-GENERATION ADAPTIVE VALIDATOR ðŸš€
    Wrapper around NextGenAdaptiveSecurityEngine to provide validator interface.
    """

    def __init__(self):
        """Initialize the next-generation adaptive validator."""
        self.engine = get_next_gen_adaptive_engine()
        logger.info("ðŸš€ NEXT-GENERATION ADAPTIVE VALIDATOR INITIALIZED! ðŸš€")

    def validate(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ðŸ§  Validate text using next-generation adaptive learning.

        Args:
            text (str): Text to validate
            context (Dict[str, Any]): Validation context

        Returns:
            Dict[str, Any]: Enhanced validation result with behavioral analysis
        """
        try:
            # Use the enhanced validation method
            result = self.engine.enhanced_validate(text, context or {})

            # Add validator-specific metadata
            result['validator_version'] = 'next_gen_adaptive_v2.0'
            result['features_enabled'] = {
                'behavioral_analysis': True,
                'context_awareness': True,
                'adaptive_learning': True,
                'threat_clustering': self.engine.enable_advanced_ml,
                'pattern_evolution': True
            }

            return result

        except Exception as e:
            logger.error(f"Next-generation adaptive validation error: {e}")
            return {
                "is_secure": False,
                "method": "next_gen_adaptive",
                "error": str(e),
                "fallback": True
            }

def get_next_gen_adaptive_validator() -> NextGenAdaptiveValidator:
    """ðŸš€ Get or create the global next-generation adaptive validator."""
    return NextGenAdaptiveValidator()
